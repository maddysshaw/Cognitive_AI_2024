{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0tVvGuLixxsclkzGVpa3L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maddysshaw/Cognitive_AI_2024/blob/main/Coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NeuroGym is a curated collection of neuroscience tasks, with a common interface,\n",
        "designed to facilitate training of neural network models on neuroscience tasks.\n",
        "\n",
        "2. (a) Initially, your goal is to train and compare multiple (at least two) models to\n",
        "perform one of these tasks. One model should be a standard recurrent neural\n",
        "network model (e.g. vanilla RNN, leaky RNN, light GRU, GRU, LSTM). One or\n",
        "more of the other models you implement should differ from the standard model\n",
        "based on a brain-inspired change (which you described in your answer to\n",
        "question 1). Describe your models including equations and schematic diagrams,\n",
        "highlighting the key differences. [10 marks]"
      ],
      "metadata": {
        "id": "1lZVMNfnYsp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import common packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time"
      ],
      "metadata": {
        "id": "FfTg6CVAakmT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Up a Vanilla RNN**"
      ],
      "metadata": {
        "id": "b2gOSfVEa7_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VanillaRNN(nn.Module):\n",
        "    \"\"\"Vanilla RNN.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "\n",
        "    Inputs:\n",
        "        input: tensor of shape (seq_len, batch, input_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "            if None, hidden is initialized through self.init_hidden()\n",
        "\n",
        "    Outputs:\n",
        "        output: tensor of shape (seq_len, batch, hidden_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def init_hidden(self, input_shape):\n",
        "        batch_size = input_shape[1]\n",
        "        return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Run network for one time step.\n",
        "\n",
        "        Inputs:\n",
        "            input: tensor of shape (batch, input_size)\n",
        "            hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "        Outputs:\n",
        "            h_new: tensor of shape (batch, hidden_size),\n",
        "                network activity at the next time step\n",
        "        \"\"\"\n",
        "        h_new = torch.tanh(self.input2h(input) + self.h2h(hidden))\n",
        "        return h_new\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propagate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialize it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "\n",
        "        # Loop through time\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "\n",
        "        # Stack together output from all time steps\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class RNNNet(nn.Module):\n",
        "    \"\"\"Recurrent network model using Vanilla RNN.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # Vanilla RNN\n",
        "        self.rnn = VanillaRNN(input_size, hidden_size, **kwargs)\n",
        "\n",
        "        # Add an output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output"
      ],
      "metadata": {
        "id": "_oTCzyplnST7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing Feedback Alignment to RNN**"
      ],
      "metadata": {
        "id": "RrdEG-g1nks0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class FeedbackAlignedRNN(nn.Module):\n",
        "    \"\"\"Feedback-aligned Vanilla RNN.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "\n",
        "    Inputs:\n",
        "        input: tensor of shape (seq_len, batch, input_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "            if None, hidden is initialized through self.init_hidden()\n",
        "\n",
        "    Outputs:\n",
        "        output: tensor of shape (seq_len, batch, hidden_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Define forward weights\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        # Define fixed random feedback weights\n",
        "        self.feedback_weights = nn.Parameter(torch.randn(hidden_size, hidden_size), requires_grad=False)\n",
        "\n",
        "    def init_hidden(self, input_shape):\n",
        "        batch_size = input_shape[1]\n",
        "        return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Run network for one time step.\"\"\"\n",
        "        h_new = torch.tanh(self.input2h(input) + self.h2h(hidden))\n",
        "        return h_new\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propagate input through the network.\"\"\"\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "\n",
        "        # Loop through time\n",
        "        output = []\n",
        "        for i in range(input.size(0)):\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "\n",
        "        # Stack outputs from all time steps\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class FA_RNNNet(nn.Module):\n",
        "    \"\"\"Recurrent network model using Feedback-Aligned RNN.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feedback-Aligned RNN\n",
        "        self.rnn = FeedbackAlignedRNN(input_size, hidden_size, **kwargs)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Feedback weights for the output layer\n",
        "        self.output_feedback_weights = nn.Parameter(torch.randn(output_size, hidden_size), requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output\n",
        "\n",
        "    def feedback_alignment_update(self, optimizer, output, target):\n",
        "        \"\"\"Custom backward pass using feedback alignment.\"\"\"\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Compute gradients for the output layer\n",
        "        output_grad = torch.autograd.grad(loss, output, create_graph=True)[0]\n",
        "\n",
        "        # Update output layer weights using fixed feedback weights\n",
        "        with torch.no_grad():\n",
        "            self.fc.weight.grad = torch.mm(output_grad, self.output_feedback_weights).t()\n",
        "            self.fc.bias.grad = output_grad.sum(dim=0)\n",
        "\n",
        "        # Compute gradients for RNN hidden weights using feedback weights\n",
        "        for i in reversed(range(output.size(0))):\n",
        "            hidden_grad = torch.mm(output_grad, self.rnn.feedback_weights)\n",
        "            for param in self.rnn.parameters():\n",
        "                if param.requires_grad:\n",
        "                    param.grad = torch.autograd.grad(output[i], param, grad_outputs=hidden_grad, retain_graph=True)[0]\n",
        "\n",
        "        # Apply optimizer step\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "FRjlP-cQpRjO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing Biological Features to the Architecture**\n",
        "Including hierarchical structure, recurrent connections, and sparsity constraints"
      ],
      "metadata": {
        "id": "yTVqepVasaES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class HierarchicalSparseRNN(nn.Module):\n",
        "    \"\"\"Hierarchical RNN with recurrent connections and sparsity constraint.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons per layer\n",
        "        num_layers: Number of RNN layers\n",
        "        sparsity_lambda: Weight of the sparsity penalty (L1 regularization)\n",
        "\n",
        "    Inputs:\n",
        "        input: tensor of shape (seq_len, batch, input_size)\n",
        "        hidden: list of tensors, each of shape (batch, hidden_size), initial hidden state for each layer\n",
        "\n",
        "    Outputs:\n",
        "        output: tensor of shape (seq_len, batch, hidden_size * num_layers)\n",
        "        hidden: list of tensors, each of shape (batch, hidden_size), final hidden state for each layer\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, sparsity_lambda=0.01, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.sparsity_lambda = sparsity_lambda\n",
        "\n",
        "        # Define layers with recurrent connections\n",
        "        self.input2h = nn.ModuleList([nn.Linear(input_size if i == 0 else hidden_size, hidden_size) for i in range(num_layers)])\n",
        "        self.h2h = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers)])\n",
        "\n",
        "        # Optional recurrent connections across layers\n",
        "        self.cross_layer_recurrent = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers - 1)])\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return [torch.zeros(batch_size, self.hidden_size) for _ in range(self.num_layers)]\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Process one time step with recurrent and cross-layer connections.\"\"\"\n",
        "        layer_hidden = []\n",
        "        current_input = input\n",
        "        sparsity_loss = 0\n",
        "\n",
        "        # Propagate through each layer\n",
        "        for i in range(self.num_layers):\n",
        "            h_new = torch.tanh(self.input2h[i](current_input) + self.h2h[i](hidden[i]))\n",
        "\n",
        "            # Add cross-layer recurrent connection\n",
        "            if i > 0:\n",
        "                h_new += torch.tanh(self.cross_layer_recurrent[i - 1](hidden[i - 1]))\n",
        "\n",
        "            # Accumulate sparsity loss\n",
        "            sparsity_loss += h_new.abs().mean()  # L1 sparsity constraint\n",
        "\n",
        "            # Store new hidden state and set input for next layer\n",
        "            layer_hidden.append(h_new)\n",
        "            current_input = h_new\n",
        "\n",
        "        return layer_hidden, sparsity_loss\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propagate input through the network.\"\"\"\n",
        "        batch_size = input.shape[1]\n",
        "\n",
        "        # Initialize hidden states if not provided\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(batch_size)\n",
        "        output = []\n",
        "        total_sparsity_loss = 0\n",
        "\n",
        "        # Process each time step\n",
        "        for t in range(input.size(0)):\n",
        "            hidden, sparsity_loss = self.recurrence(input[t], hidden)\n",
        "            output.append(torch.cat(hidden, dim=-1))  # Concatenate all layers’ hidden states for output\n",
        "            total_sparsity_loss += sparsity_loss\n",
        "\n",
        "        # Stack outputs and apply sparsity constraint\n",
        "        output = torch.stack(output, dim=0)\n",
        "        total_sparsity_loss /= input.size(0)  # Average over timesteps\n",
        "\n",
        "        return output, hidden, self.sparsity_lambda * total_sparsity_loss\n",
        "\n",
        "\n",
        "class HS_RNNNet(nn.Module):\n",
        "    \"\"\"Recurrent network with hierarchical sparse RNN.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size per layer\n",
        "        output_size: int, output size\n",
        "        num_layers: int, number of RNN layers\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, hidden_size * num_layers)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, sparsity_lambda=0.01, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # Hierarchical Sparse RNN\n",
        "        self.rnn = HierarchicalSparseRNN(input_size, hidden_size, num_layers, sparsity_lambda=sparsity_lambda, **kwargs)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(hidden_size * num_layers, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _, sparsity_loss = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output, sparsity_loss\n"
      ],
      "metadata": {
        "id": "grYZrGTMslAw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. (b) Compare your models both in how well they learn to perform the task, and by\n",
        "analysing the hidden unit activity of the trained models to understand how the\n",
        "trained models solve the task. Highlight and interpret any differences between\n",
        "the models. [20 marks]\n",
        "\n"
      ],
      "metadata": {
        "id": "jmFZCTF6ZKes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import task from neurogym library"
      ],
      "metadata": {
        "id": "lku5MoaO4g5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install neurogym to use cognitive tasks\n",
        "! git clone https://github.com/neurogym/neurogym.git\n",
        "%cd neurogym/\n",
        "! pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoGpb9_VZZ5e",
        "outputId": "8f690eab-725b-4fc6-fe5f-9c39f9b16f0d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'neurogym'...\n",
            "remote: Enumerating objects: 11100, done.\u001b[K\n",
            "remote: Counting objects: 100% (1001/1001), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 11100 (delta 928), reused 898 (delta 898), pack-reused 10099 (from 1)\u001b[K\n",
            "Receiving objects: 100% (11100/11100), 8.17 MiB | 9.33 MiB/s, done.\n",
            "Resolving deltas: 100% (8335/8335), done.\n",
            "/content/neurogym\n",
            "Obtaining file:///content/neurogym\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from neurogym==0.0.2) (1.26.4)\n",
            "Collecting gym<0.25,>=0.20.0 (from neurogym==0.0.2)\n",
            "  Downloading gym-0.24.1.tar.gz (696 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m696.4/696.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from neurogym==0.0.2) (3.8.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym<0.25,>=0.20.0->neurogym==0.0.2) (3.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<0.25,>=0.20.0->neurogym==0.0.2) (0.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->neurogym==0.0.2) (1.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.24.1-py3-none-any.whl size=793122 sha256=fe98b0dafa94281aa59fb7c648e23fdf751bf5adb1b6de45561c7606ddf76e80\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/fb/19/388995b88cb551717a8dff40c889172cd12fadf994216a0a22\n",
            "Successfully built gym\n",
            "Installing collected packages: gym, neurogym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Running setup.py develop for neurogym\n",
            "Successfully installed gym-0.24.1 neurogym-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# @title import the task from the neurogym library\n",
        "\n",
        "import neurogym as ngym\n",
        "\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(level=logging.CRITICAL)\n",
        "\n",
        "# Environment\n",
        "task = 'PerceptualDecisionMaking-v0'\n",
        "timing = {\n",
        "    'fixation': ('choice', (50, 100, 200, 400)),\n",
        "    'stimulus': ('choice', (100, 200, 400, 800)),\n",
        "}\n",
        "kwargs = {'dt': 20, 'timing': timing}\n",
        "seq_len = 100\n",
        "\n",
        "# Make supervised dataset\n",
        "dataset = ngym.Dataset(task, env_kwargs=kwargs, batch_size=16,\n",
        "                       seq_len=seq_len)\n",
        "\n",
        "# A sample environment from dataset\n",
        "env = dataset.env\n",
        "# Visualize the environment with 2 sample trials\n",
        "_ = ngym.utils.plot_env(env, num_trials=2)\n",
        "\n",
        "# Network input and output size\n",
        "input_size = env.observation_space.shape[0]\n",
        "output_size = env.action_space.n"
      ],
      "metadata": {
        "id": "4M8vFAVLZbRv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Networks on Decision Making Tasks"
      ],
      "metadata": {
        "id": "-eqorGLb43LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(level=logging.CRITICAL)\n",
        "\n",
        "# Assuming Net is defined somewhere and dataset() function is defined\n",
        "# Assuming input_size and output_size are also defined\n",
        "\n",
        "# Instantiate the network\n",
        "hidden_size = 50\n",
        "net = RNNNet(input_size=input_size, hidden_size=hidden_size,\n",
        "          output_size=output_size, dt=env.dt, sigma_rec=0.15)\n",
        "print(net)\n",
        "\n",
        "# Use Adam optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss_values = []  # List to store loss values\n",
        "running_loss = 0.0\n",
        "print_step = 200\n",
        "for i in range(5000):\n",
        "    inputs, labels = dataset()\n",
        "    inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "    labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "    # Zero the gradient buffers\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output, activity = net(inputs)\n",
        "    output = output.view(-1, output_size)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update running loss\n",
        "    running_loss += loss.item()\n",
        "    if i % print_step == (print_step - 1):\n",
        "        average_loss = running_loss / print_step\n",
        "        print('Step {}, Loss {:0.4f}'.format(i+1, average_loss))\n",
        "        loss_values.append(average_loss)  # Append average loss here\n",
        "        running_loss = 0.0\n",
        "\n",
        "# Plotting the learning curve\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Vanilla RNN Learning Curve\")\n",
        "plt.plot(loss_values, label='Loss')\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6_CSAxvb49SD",
        "outputId": "417ad012-b6b0-4473-a45b-82e907e3a69d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNNet(\n",
            "  (rnn): VanillaRNN(\n",
            "    (input2h): Linear(in_features=3, out_features=50, bias=True)\n",
            "    (h2h): Linear(in_features=50, out_features=50, bias=True)\n",
            "  )\n",
            "  (fc): Linear(in_features=50, out_features=3, bias=True)\n",
            ")\n",
            "Step 200, Loss 0.2649\n",
            "Step 400, Loss 0.1225\n",
            "Step 600, Loss 0.0772\n",
            "Step 800, Loss 0.0683\n",
            "Step 1000, Loss 0.0662\n",
            "Step 1200, Loss 0.0633\n",
            "Step 1400, Loss 0.0622\n",
            "Step 1600, Loss 0.0618\n",
            "Step 1800, Loss 0.0617\n",
            "Step 2000, Loss 0.0587\n",
            "Step 2200, Loss 0.0594\n",
            "Step 2400, Loss 0.0582\n",
            "Step 2600, Loss 0.0578\n",
            "Step 2800, Loss 0.0580\n",
            "Step 3000, Loss 0.0586\n",
            "Step 3200, Loss 0.0566\n",
            "Step 3400, Loss 0.0566\n",
            "Step 3600, Loss 0.0566\n",
            "Step 3800, Loss 0.0561\n",
            "Step 4000, Loss 0.0571\n",
            "Step 4200, Loss 0.0554\n",
            "Step 4400, Loss 0.0568\n",
            "Step 4600, Loss 0.0567\n",
            "Step 4800, Loss 0.0574\n",
            "Step 5000, Loss 0.0574\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(level=logging.CRITICAL)\n",
        "\n",
        "# Assuming Net is defined somewhere and dataset() function is defined\n",
        "# Assuming input_size and output_size are also defined\n",
        "\n",
        "# Instantiate the network\n",
        "hidden_size = 50\n",
        "net = FA_RNNNet(input_size=input_size, hidden_size=hidden_size,\n",
        "          output_size=output_size, dt=env.dt, sigma_rec=0.15)\n",
        "print(net)\n",
        "\n",
        "# Use Adam optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss_values = []  # List to store loss values\n",
        "running_loss = 0.0\n",
        "print_step = 200\n",
        "for i in range(5000):\n",
        "    inputs, labels = dataset()\n",
        "    inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "    labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "    # Zero the gradient buffers\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output, activity = net(inputs)\n",
        "    output = output.view(-1, output_size)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update running loss\n",
        "    running_loss += loss.item()\n",
        "    if i % print_step == (print_step - 1):\n",
        "        average_loss = running_loss / print_step\n",
        "        print('Step {}, Loss {:0.4f}'.format(i+1, average_loss))\n",
        "        loss_values.append(average_loss)  # Append average loss here\n",
        "        running_loss = 0.0\n",
        "\n",
        "# Plotting the learning curve\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"FA RNN Learning Curve\")\n",
        "plt.plot(loss_values, label='Loss')\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wCLlc5Y65REY",
        "outputId": "3bbb8eb2-8c94-4198-f0f8-8827942a965a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FA_RNNNet(\n",
            "  (rnn): FeedbackAlignedRNN(\n",
            "    (input2h): Linear(in_features=3, out_features=50, bias=True)\n",
            "    (h2h): Linear(in_features=50, out_features=50, bias=True)\n",
            "  )\n",
            "  (fc): Linear(in_features=50, out_features=3, bias=True)\n",
            ")\n",
            "Step 200, Loss 0.3006\n",
            "Step 400, Loss 0.1370\n",
            "Step 600, Loss 0.0850\n",
            "Step 800, Loss 0.0744\n",
            "Step 1000, Loss 0.0678\n",
            "Step 1200, Loss 0.0633\n",
            "Step 1400, Loss 0.0626\n",
            "Step 1600, Loss 0.0617\n",
            "Step 1800, Loss 0.0591\n",
            "Step 2000, Loss 0.0601\n",
            "Step 2200, Loss 0.0578\n",
            "Step 2400, Loss 0.0574\n",
            "Step 2600, Loss 0.0573\n",
            "Step 2800, Loss 0.0591\n",
            "Step 3000, Loss 0.0589\n",
            "Step 3200, Loss 0.0575\n",
            "Step 3400, Loss 0.0576\n",
            "Step 3600, Loss 0.0559\n",
            "Step 3800, Loss 0.0565\n",
            "Step 4000, Loss 0.0572\n",
            "Step 4200, Loss 0.0556\n",
            "Step 4400, Loss 0.0571\n",
            "Step 4600, Loss 0.0576\n",
            "Step 4800, Loss 0.0580\n",
            "Step 5000, Loss 0.0560\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(level=logging.CRITICAL)\n",
        "\n",
        "# Assuming Net is defined somewhere and dataset() function is defined\n",
        "# Assuming input_size and output_size are also defined\n",
        "\n",
        "# Instantiate the network\n",
        "hidden_size = 50\n",
        "net = HS_RNNNet(input_size=input_size, hidden_size=hidden_size, num_layers=4, sparsity_lambda=0.01,\n",
        "          output_size=output_size, dt=env.dt, sigma_rec=0.15)\n",
        "print(net)\n",
        "\n",
        "# Use Adam optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss_values = []  # List to store loss values\n",
        "running_loss = 0.0\n",
        "print_step = 200\n",
        "for i in range(5000):\n",
        "    inputs, labels = dataset()\n",
        "    inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "    labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "    # Zero the gradient buffers\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output, activity = net(inputs)\n",
        "    output = output.view(-1, output_size)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update running loss\n",
        "    running_loss += loss.item()\n",
        "    if i % print_step == (print_step - 1):\n",
        "        average_loss = running_loss / print_step\n",
        "        print('Step {}, Loss {:0.4f}'.format(i+1, average_loss))\n",
        "        loss_values.append(average_loss)  # Append average loss here\n",
        "        running_loss = 0.0\n",
        "\n",
        "# Plotting the learning curve\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"HS RNN Learning Curve\")\n",
        "plt.plot(loss_values, label='Loss')\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "WWFY4RfC5aIm",
        "outputId": "e3827802-0b13-425b-cb62-4940957787b6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HS_RNNNet(\n",
            "  (rnn): HierarchicalSparseRNN(\n",
            "    (input2h): ModuleList(\n",
            "      (0): Linear(in_features=3, out_features=50, bias=True)\n",
            "      (1-3): 3 x Linear(in_features=50, out_features=50, bias=True)\n",
            "    )\n",
            "    (h2h): ModuleList(\n",
            "      (0-3): 4 x Linear(in_features=50, out_features=50, bias=True)\n",
            "    )\n",
            "    (cross_layer_recurrent): ModuleList(\n",
            "      (0-2): 3 x Linear(in_features=50, out_features=50, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=200, out_features=3, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-120273dc4577>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. (c) Using the same models, train them to solve a second task from NeuroGym, and\n",
        "analyse them as in b). Do your conclusions from b) hold for this second task? [20 marks]\n"
      ],
      "metadata": {
        "id": "_EXp_pH_ZNiL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TJd2twwcZb9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. (d) These marks are reserved for something original. Some possibilities could be\n",
        "training networks with a totally different architecture, implementing a different\n",
        "type of learning (e.g. reinforcement), implementing neuromodulation, training\n",
        "on multiple tasks at once, or many tasks or anything else unexpected. Anything\n",
        "presented in this section should be done so in comparison with what you know\n",
        "about how brains and standard ML/AI models learn. This part is only worth 20%\n",
        "of the coursework marks [10% of total], so please do not spend a\n",
        "disproportionate amount of time on it. [20 marks]"
      ],
      "metadata": {
        "id": "oR1sx2_aZRhX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3obSxakLZcvx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}